{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b3d1e6",
   "metadata": {},
   "source": [
    "## Pandas Optimization - Advance Techniques\n",
    "\n",
    "- Chunking\n",
    "- Indexing\n",
    "- Vector Operations\n",
    "- Memory Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f86bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bcdd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2232854f",
   "metadata": {},
   "source": [
    "### Chunking\n",
    "\n",
    "For large datasets, read data in chunks using the chunksize parameter in functions like pd.read_csv(). Process each chunk independently to avoid memory overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e359f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with chunking: 98.83 MiB\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'large_file.csv'\n",
    "def read_with_chunking():\n",
    "    # Measure time for reading with chunking\n",
    "    start_time = time.time()\n",
    "    chunks = []\n",
    "    chunk_size = 100000  # Adjust chunk size as needed\n",
    "\n",
    "    for chunk in pd.read_csv(csv_file_path, chunksize=chunk_size):\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    df_chunked = pd.concat(chunks, ignore_index=True)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return df_chunked, end_time - start_time\n",
    "\n",
    "# Measure memory usage\n",
    "mem_usage_with_chunking = memory_usage(read_with_chunking)\n",
    "print(f\"Memory usage with chunking: {max(mem_usage_with_chunking) - min(mem_usage_with_chunking):.2f} MiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6d6876",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "Setting an appropriate index can drastically speed up lookups, joins, and group operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f640445a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken without indexing: 0.15232062339782715\n",
      "Time taken with indexing: 0.06646132469177246\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Create large DataFrames\n",
    "df1 = pd.DataFrame({'key': range(10000000), 'value1': range(10000000)})\n",
    "df2 = pd.DataFrame({'key': range(10000000), 'value2': range(10000000)})\n",
    "\n",
    "# Merge without indexing\n",
    "start_time = time.time()\n",
    "merged_df_no_index = pd.merge(df1, df2, on='key')\n",
    "end_time = time.time()\n",
    "print(\"Time taken without indexing:\", end_time - start_time)\n",
    "\n",
    "# Merge with indexing\n",
    "df1.set_index('key', inplace=True)\n",
    "df2.set_index('key', inplace=True)\n",
    "\n",
    "start_time = time.time()\n",
    "merged_df_with_index = pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "end_time = time.time()\n",
    "print(\"Time taken with indexing:\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece48f16",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "Vectorized operations allow you to perform computations on entire columns or arrays without explicit loops, which can significantly speed up operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75fe4df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.9784\n",
      "Time taken: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': np.random.randint(0, 100, size=10000),\n",
    "    'B': np.random.randint(0, 100, size=10000)\n",
    "})\n",
    "\n",
    "df['C'] = 0\n",
    "start_time = time.time()\n",
    "# Use a loop to add the values of columns 'A' and 'B'\n",
    "for i in range(len(df)):\n",
    "    df['C'][i] = df['A'][i] + df['B'][i]\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time-start_time:.4f}\")\n",
    "\n",
    "# Vectorized operation: adding two columns\n",
    "start_time = time.time()\n",
    "df['C'] = df['A'] + df['B']\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time-start_time:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb31a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 4.7028\n",
      "Time taken: 0.0089\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'A': np.random.randint(0, 100, size=10000000),  # int64\n",
    "})\n",
    "\n",
    "start_time = time.time()\n",
    "df['B'] = df['A'].apply(lambda x: x ** 2)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time-start_time:.4f}\")\n",
    "\n",
    "# vectorization\n",
    "start_time = time.time()\n",
    "df['B'] = df['A'] ** 2 \n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time-start_time:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6339b0f",
   "metadata": {},
   "source": [
    "### Memory Profiling\n",
    "\n",
    "Use profiling tools like Pandas-Profiling or memory_profiler to identify bottlenecks and memory hogs in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1496187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/memory_profiler.py\", line 1351, in <module>\n",
      "    exec_with_profiler(script_filename, prof, args.backend, script_args)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/memory_profiler.py\", line 1252, in exec_with_profiler\n",
      "    exec(compile(f.read(), filename, 'exec'), ns, ns)\n",
      "  File \"memory.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/compat/__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n",
      "AttributeError: _ARRAY_API not found\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/memory_profiler.py\", line 1351, in <module>\n",
      "    exec_with_profiler(script_filename, prof, args.backend, script_args)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/memory_profiler.py\", line 1252, in exec_with_profiler\n",
      "    exec(compile(f.read(), filename, 'exec'), ns, ns)\n",
      "  File \"memory.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/dtypes/dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n",
      "AttributeError: _ARRAY_API not found\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/memory_profiler.py\", line 1351, in <module>\n",
      "    exec_with_profiler(script_filename, prof, args.backend, script_args)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/memory_profiler.py\", line 1252, in exec_with_profiler\n",
      "    exec(compile(f.read(), filename, 'exec'), ns, ns)\n",
      "  File \"memory.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/arrow/array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/opt/anaconda3/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/numexpr/__init__.py\", line 26, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n",
      "AttributeError: _ARRAY_API not found\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/memory_profiler.py\", line 1351, in <module>\n",
      "    exec_with_profiler(script_filename, prof, args.backend, script_args)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/memory_profiler.py\", line 1252, in exec_with_profiler\n",
      "    exec(compile(f.read(), filename, 'exec'), ns, ns)\n",
      "  File \"memory.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/arrow/array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/core/nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/opt/anaconda3/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/bottleneck/__init__.py\", line 2, in <module>\n",
      "    from .reduce import (\n",
      "AttributeError: _ARRAY_API not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: memory.py\r\n",
      "\r\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\r\n",
      "=============================================================\r\n",
      "     4     94.5 MiB     94.5 MiB           1   @profile\r\n",
      "     5                                         def process_data():\r\n",
      "     6    125.2 MiB     30.7 MiB           1       df = pd.DataFrame({'a': range(1000000), 'b': range(1000000)})\r\n",
      "     7    125.4 MiB      0.2 MiB           1       df['c'] = df['a'] + df['b']\r\n",
      "     8    141.0 MiB     15.6 MiB           1       df = df.drop(columns=['a'])\r\n",
      "     9    141.0 MiB      0.0 MiB           1       return df\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python -m memory_profiler memory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307b134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
